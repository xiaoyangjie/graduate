# -*- coding: UTF-8 -*-from TwitterAPI import TwitterRequestErrorfrom TwitterTweetCapture.api.API import APIimport timeimport pymongofrom pymongo.errors import DuplicateKeyErrorimport reimport requests"""功能：    根据关键字，实现网页的推文采集__author__ = YJ__version__ = 1.0"""def searchTimelineCapture(id,keyword=None,proxy=None):    """    返回推特ID列表    :param id: 每次的最后一个ID，不用管    :param keyword: 关键字  如melbourne%20siege    :return:    """    proxies = {'http': 'http://%s' %proxy,               'https': 'http://%s' %proxy}    HTTP_HEADER = {'Connection': 'Keep-Alive',                   'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',                   'Accept-Language': 'en-US,en;q=0.8,zh-Hans-CN;q=0.5,zh-Hans;q=0.3',                   'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 '                                 '(KHTML, like Gecko) Chrome/31.0.1650.63 Safari/537.36',                   }    URL = 'https://twitter.com/i/search/timeline?q=' + keyword + '&max_position=TWEET-'    print URL    if id == 1:        URL = URL + '1'    else:        URL = URL + str(id) + '-' + str(id)    r = requests.get(URL, headers=HTTP_HEADER, proxies=proxies)    s = r.content    p = re.compile(r'stream-item-tweet-(.*?)\\')    result = re.findall(p,s)    _result = []    for id in result:        _result.append(int(id))    return _resultdef twitterWebKeywords(proxy=None,mongodb=None,mongoDataName=None, mongoColName=None, minTime=1,                       keyword=None):    """    :param proxy: 代理，如192.168.1.148:8188    :param mongodb: mongodb的host    :param mongoDataName:  数据库    :param mongoColName:  集合    :param minTime:  UTC + 8 * 3600的时间    :param keyword:  关键词，如kill    :return: None    """    token =   {'consumer_key': "fO4lXV6LLz5e1Ew6uRDtvXpIQ",                  'consumer_secret': "LivsS9DTKh4Xmfo2vOG2tpKmrj8lxsYqiDgZLamPBJahFqnjUo",                  'access_token': "713024459158859776-V7r3cttVw77ESAgxl3k4OU6iIsyubbd",                  'access_token_secret': "0oxHNzRbnPM8tDI2IC0HtvmiPV1PFNfi40YuQNQfoskAR"}    #设置代理和token    api = API(proxy=proxy,token=token)    #设置数据存放的集合    client = pymongo.MongoClient(mongodb)[mongoDataName][mongoColName]    _id = 1  #用于当采集推文发生网络错误等情况时，记录采集到了哪条推文的ID    flag = False    while True:        try:            idList = searchTimelineCapture(_id,keyword=keyword,proxy=proxy) #获取一页的id列表        except :            #发生网络等错误，继续重新采集            continue        for id in idList:            print id            try:                r = api.rest_find_one_tweet(id) #找到对应的推文            except TwitterRequestError as TwiReqError:                time.sleep(15)                while True:                    try:                        r = api.rest_find_one_tweet(id)                        break                    except TwitterRequestError as TwiReqError:                        time.sleep(15)            except:continue            client.insert(r)   #插入数据库            _id = id            try:                created_at = int(time.mktime(time.strptime(r['created_at'], "%a %b %d %H:%M:%S +0000 %Y"))) + 8 * 3600                if created_at < minTime:  # 超过最小时间，停止程序                    flag = True                    break            except:pass        if flag:            breakif __name__ == '__main__':    mongodb = 'mongodb://kb314:fzdwxxcl.314@121.49.99.14:30011' #mongodb    proxy = '192.168.1.148:8118'  #代理    mongoDataName = 'test' #数据库名字    mongoColName = '12'  #集合名字    keyword = 'ALSEN'  #关键字,随意输入  这个没有转义字符  如 #是 23%    minTime = 1510761600  #设置爬取到什么时间停止，这个是UTC+8*3600的秒数，需要去http://tool.chinaz.com/Tools/unixtime.aspx转换    twitterWebKeywords(proxy=proxy,mongodb=mongodb,mongoDataName=mongoDataName, mongoColName=mongoColName,                       keyword=keyword, minTime=minTime)